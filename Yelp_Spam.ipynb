{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uw0z8NBGBLdO"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "import getpass\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import time\n",
        "import logging\n",
        "from scipy.sparse import hstack\n",
        "def get_db_credentials():\n",
        "    \"\"\"Prompt user for MySQL credentials securely.\"\"\"\n",
        "    user = input(\"Enter MySQL username: \")\n",
        "    password = getpass.getpass(\"Enter MySQL password: \")  # Hides password input\n",
        "    return user, password\n",
        "\n",
        "def fetch_data_from_databases(user, password, host, databases, cache_file=\"yelp_data_cache.pkl\", force_refresh=False):\n",
        "    \"\"\"Fetch data from multiple databases with caching and detailed output.\"\"\"\n",
        "    if not force_refresh and os.path.exists(cache_file):\n",
        "        print(f\"\\nLoading cached data from {cache_file}...\")\n",
        "        start_time = time.time()\n",
        "        with open(cache_file, 'rb') as f:\n",
        "            db_data = pickle.load(f)\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Mimic the database fetch output for cached data\n",
        "        for db in db_data:\n",
        "            print(f\"\\nConnecting to {db} (cached)...\")\n",
        "            table_list = list(db_data[db].keys())\n",
        "            print(f\"Tables in {db}: {table_list}\")\n",
        "            for table in table_list:\n",
        "                df = db_data[db][table]\n",
        "                print(f\"Fetching data from {table} (cached)...\")\n",
        "                print(f\"Loaded {table} with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
        "                print(\"Columns and Data Types:\")\n",
        "                for col, dtype in df.dtypes.items():\n",
        "                    print(f\"  {col}: {dtype}\")\n",
        "            print(f\"Time taken for {db}: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "        print(f\"\\n✅ Cached data loaded! Total time: {end_time - start_time:.2f} seconds\")\n",
        "        return db_data\n",
        "\n",
        "    # If no cache or force_refresh is True, fetch from databases\n",
        "    db_data = {}\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    for db in databases:\n",
        "        print(f\"\\nConnecting to {db}...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Create SQLAlchemy engine for the database\n",
        "        engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}/{db}\")\n",
        "\n",
        "        # Get all table names from the database\n",
        "        query_tables = \"SHOW TABLES;\"\n",
        "        tables = pd.read_sql(query_tables, engine)\n",
        "        table_list = tables.iloc[:, 0].tolist()\n",
        "        print(f\"Tables in {db}: {table_list}\")\n",
        "\n",
        "        # Store data for each table in a dictionary\n",
        "        db_data[db] = {}\n",
        "\n",
        "        # Loop through each table and load data\n",
        "        for table in table_list:\n",
        "            print(f\"Fetching data from {table}...\")\n",
        "            query = f\"SELECT * FROM {table};\"\n",
        "            df = pd.read_sql(query, engine)\n",
        "            db_data[db][table] = df\n",
        "            print(f\"Loaded {table} with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
        "            print(\"Columns and Data Types:\")\n",
        "            for col, dtype in df.dtypes.items():\n",
        "                print(f\"  {col}: {dtype}\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"Time taken for {db}: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    total_end_time = time.time()\n",
        "    print(f\"\\n✅ Data fetching complete! Total time: {total_end_time - total_start_time:.2f} seconds\")\n",
        "\n",
        "    # Save to cache\n",
        "    print(f\"Saving data to cache file: {cache_file}...\")\n",
        "    with open(cache_file, 'wb') as f:\n",
        "        pickle.dump(db_data, f)\n",
        "    print(\"✅ Cache saved successfully!\")\n",
        "\n",
        "    return db_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "host = \"database-ml2025.cvk6uwuwc2j4.us-east-2.rds.amazonaws.com\"\n",
        "databases = [\"yelp_hotel\", \"yelp_res\"]\n",
        "# Get credentials\n",
        "user, password = get_db_credentials()\n",
        "# Fetch data\n",
        "data = fetch_data_from_databases(user, password, host, databases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QEtNestMBe7N",
        "outputId": "e54bf7e4-d5d1-4608-8684-dc6c3e20c003"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter MySQL username: admin\n",
            "Enter MySQL password: ··········\n",
            "\n",
            "Loading cached data from yelp_data_cache.pkl...\n",
            "\n",
            "Connecting to yelp_hotel (cached)...\n",
            "Tables in yelp_hotel: ['author_features', 'hotel', 'review', 'review_features', 'reviewer']\n",
            "Fetching data from author_features (cached)...\n",
            "Loaded author_features with 1716 rows and 7 columns\n",
            "Columns and Data Types:\n",
            "  Author_ID: object\n",
            "  Author_ID_m: int64\n",
            "  No_Of_Reviews: int64\n",
            "  P_Filtered: float64\n",
            "  MNR: int64\n",
            "  BST: float64\n",
            "  Review_Count: int64\n",
            "Fetching data from hotel (cached)...\n",
            "Loaded hotel with 282974 rows and 13 columns\n",
            "Columns and Data Types:\n",
            "  hotelID: object\n",
            "  name: object\n",
            "  location: object\n",
            "  reviewCount: int64\n",
            "  rating: int64\n",
            "  categories: object\n",
            "  address: object\n",
            "  AcceptsCreditCards: object\n",
            "  PriceRange: object\n",
            "  WiFi: object\n",
            "  webSite: object\n",
            "  phoneNumber: object\n",
            "  filReviewCount: float64\n",
            "Fetching data from review (cached)...\n",
            "Loaded review with 688313 rows and 10 columns\n",
            "Columns and Data Types:\n",
            "  date: object\n",
            "  reviewID: object\n",
            "  reviewerID: object\n",
            "  reviewContent: object\n",
            "  rating: int64\n",
            "  usefulCount: int64\n",
            "  coolCount: int64\n",
            "  funnyCount: int64\n",
            "  flagged: object\n",
            "  hotelID: object\n",
            "Fetching data from review_features (cached)...\n",
            "Loaded review_features with 134480 rows and 8 columns\n",
            "Columns and Data Types:\n",
            "  Review_ID: object\n",
            "  Review_ID_m: int64\n",
            "  Author_ID: object\n",
            "  Author_ID_m: int64\n",
            "  EXT: int64\n",
            "  DEV: float64\n",
            "  Filtered: int64\n",
            "  Review_Body: object\n",
            "Fetching data from reviewer (cached)...\n",
            "Loaded reviewer with 5122 rows and 13 columns\n",
            "Columns and Data Types:\n",
            "  reviewerID: object\n",
            "  name: object\n",
            "  location: object\n",
            "  yelpJoinDate: object\n",
            "  friendCount: int64\n",
            "  reviewCount: int64\n",
            "  firstCount: int64\n",
            "  usefulCount: int64\n",
            "  coolCount: int64\n",
            "  funnyCount: int64\n",
            "  complimentCount: int64\n",
            "  tipCount: int64\n",
            "  fanCount: int64\n",
            "Time taken for yelp_hotel: 6.69 seconds\n",
            "\n",
            "Connecting to yelp_res (cached)...\n",
            "Tables in yelp_res: ['author_features', 'restaurant', 'review', 'review_features', 'reviewer']\n",
            "Fetching data from author_features (cached)...\n",
            "Loaded author_features with 3124 rows and 7 columns\n",
            "Columns and Data Types:\n",
            "  Author_ID: object\n",
            "  Author_ID_m: int64\n",
            "  No_Of_Reviews: int64\n",
            "  P_Filtered: float64\n",
            "  MNR: int64\n",
            "  BST: float64\n",
            "  Review_Count: int64\n",
            "Fetching data from restaurant (cached)...\n",
            "Loaded restaurant with 242650 rows and 30 columns\n",
            "Columns and Data Types:\n",
            "  restaurantID: object\n",
            "  name: object\n",
            "  location: object\n",
            "  reviewCount: int64\n",
            "  rating: int64\n",
            "  categories: object\n",
            "  address: object\n",
            "  Hours: object\n",
            "  GoodforKids: object\n",
            "  AcceptsCreditCards: object\n",
            "  Parking: object\n",
            "  Attire: object\n",
            "  GoodforGroups: object\n",
            "  PriceRange: object\n",
            "  TakesReservations: object\n",
            "  Delivery: object\n",
            "  Takeout: object\n",
            "  WaiterService: object\n",
            "  OutdoorSeating: object\n",
            "  WiFi: object\n",
            "  GoodFor: object\n",
            "  Alcohol: object\n",
            "  NoiseLevel: object\n",
            "  Ambience: object\n",
            "  HasTV: object\n",
            "  Caters: object\n",
            "  WheelchairAccessible: object\n",
            "  webSite: object\n",
            "  phoneNumber: object\n",
            "  filReviewCount: int64\n",
            "Fetching data from review (cached)...\n",
            "Loaded review with 788289 rows and 10 columns\n",
            "Columns and Data Types:\n",
            "  date: object\n",
            "  reviewID: object\n",
            "  reviewerID: object\n",
            "  reviewContent: object\n",
            "  rating: int64\n",
            "  usefulCount: int64\n",
            "  coolCount: int64\n",
            "  funnyCount: int64\n",
            "  flagged: object\n",
            "  restaurantID: object\n",
            "Fetching data from review_features (cached)...\n",
            "Loaded review_features with 113323 rows and 8 columns\n",
            "Columns and Data Types:\n",
            "  Review_ID: object\n",
            "  Review_ID_m: int64\n",
            "  Author_ID: object\n",
            "  Author_ID_m: int64\n",
            "  EXT: int64\n",
            "  DEV: float64\n",
            "  Filtered: int64\n",
            "  Review_Body: object\n",
            "Fetching data from reviewer (cached)...\n",
            "Loaded reviewer with 16941 rows and 13 columns\n",
            "Columns and Data Types:\n",
            "  reviewerID: object\n",
            "  name: object\n",
            "  location: object\n",
            "  yelpJoinDate: object\n",
            "  friendCount: int64\n",
            "  reviewCount: int64\n",
            "  firstCount: int64\n",
            "  usefulCount: int64\n",
            "  coolCount: int64\n",
            "  funnyCount: int64\n",
            "  complimentCount: int64\n",
            "  tipCount: int64\n",
            "  fanCount: int64\n",
            "Time taken for yelp_res: 6.69 seconds\n",
            "\n",
            "✅ Cached data loaded! Total time: 6.69 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Logging setup ===\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.FileHandler('training_with_ensemble.log'), logging.StreamHandler()]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# === Fast tokenizer without NLTK ===\n",
        "stop_words = set([\n",
        "    'the', 'and', 'is', 'in', 'to', 'it', 'of', 'for', 'on', 'this', 'that', 'with', 'as', 'was', 'but', 'are', 'have',\n",
        "    'be', 'at', 'or', 'an', 'not', 'by', 'from', 'they', 'we', 'you', 'had', 'his', 'her', 'its', 'can', 'my', 'all',\n",
        "    'if', 'there', 'been', 'so', 'no', 'out', 'up', 'what', 'when', 'which', 'who', 'would', 'will', 'just', 'about'\n",
        "])\n",
        "\n",
        "def extract_text_features(text):\n",
        "    if pd.isna(text):\n",
        "        return ''\n",
        "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    return ' '.join([word for word in tokens if word not in stop_words])\n",
        "\n",
        "# === Data Preparation ===\n",
        "def prepare_data(db_data, db_name, sample_frac=0.1):\n",
        "    logger.info(f\"Starting data preparation for {db_name}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    reviews_df = db_data[db_name]['review'].sample(frac=sample_frac, random_state=42).copy()\n",
        "    logger.info(f\"Unique values in 'flagged' for {db_name}.review: {reviews_df['flagged'].unique().tolist()}\")\n",
        "    reviews_df['is_fake'] = reviews_df['flagged'].map({'YR': 1, 'Y': 1, 'NR': 0, 'N': 0})\n",
        "    logger.info(f\"Number of NaN in 'is_fake': {reviews_df['is_fake'].isna().sum()}\")\n",
        "    reviews_df = reviews_df.dropna(subset=['is_fake'])\n",
        "\n",
        "    review_features_df = db_data[db_name]['review_features']\n",
        "    author_features_df = db_data[db_name]['author_features']\n",
        "\n",
        "    df = reviews_df.merge(review_features_df[['Review_ID', 'EXT', 'DEV', 'Filtered']],\n",
        "                          left_on='reviewID', right_on='Review_ID', how='left')\n",
        "    df = df.merge(author_features_df[['Author_ID', 'No_Of_Reviews', 'P_Filtered', 'MNR', 'BST']],\n",
        "                  left_on='reviewerID', right_on='Author_ID', how='left')\n",
        "\n",
        "    df['clean_text'] = df['reviewContent'].apply(extract_text_features)\n",
        "    df['review_length'] = df['reviewContent'].str.len()\n",
        "\n",
        "    logger.info(f\"Finished data preparation for {db_name} in {time.time() - start_time:.2f} seconds\")\n",
        "    return df\n",
        "\n",
        "# === Optional PCA (you can skip if memory is an issue) ===\n",
        "def apply_pca(X, db_name):\n",
        "    logger.info(f\"Applying PCA for {db_name}\")\n",
        "    pca = PCA()\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    explained_variance = pca.explained_variance_ratio_\n",
        "    logger.info(f\"PCA Explained Variance Ratios for {db_name}: {explained_variance[:10]}\")\n",
        "    logger.info(f\"Cumulative Explained Variance for {db_name}: {np.cumsum(explained_variance)[:10]}\")\n",
        "    return X_pca, pca\n",
        "\n",
        "# === Feature Selection (Chi-squared) ===\n",
        "def select_features(X, y, db_name, k=50):\n",
        "    logger.info(f\"Selecting top {k} features for {db_name}\")\n",
        "    selector = SelectKBest(score_func=chi2, k=k)\n",
        "    X_selected = selector.fit_transform(X, y)\n",
        "    selected_indices = selector.get_support(indices=True)\n",
        "    logger.info(f\"Selected feature indices for {db_name}: {selected_indices}\")\n",
        "    return X_selected, selected_indices\n",
        "\n",
        "# === Model Training and Evaluation ===\n",
        "def train_and_evaluate(df, db_name):\n",
        "    logger.info(f\"Starting training for {db_name}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
        "    X_text = tfidf.fit_transform(df['clean_text'])\n",
        "    X_other = df[['rating', 'EXT', 'DEV', 'No_Of_Reviews', 'P_Filtered', 'MNR', 'BST', 'review_length']].fillna(0).values\n",
        "    scaler = MinMaxScaler()\n",
        "    X_other_scaled = scaler.fit_transform(X_other)\n",
        "\n",
        "    # Use sparse stacking to avoid out-of-memory\n",
        "    X = hstack([X_text, X_other_scaled])\n",
        "    y = df['is_fake']\n",
        "\n",
        "    # Optionally apply PCA (not recommended if running into memory issues)\n",
        "    # X_pca, pca = apply_pca(X, db_name)\n",
        "\n",
        "    # Feature Selection\n",
        "    X_selected, selected_indices = select_features(X, y, db_name, k=50)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train_selected = X_train[:, selected_indices]\n",
        "    X_test_selected = X_test[:, selected_indices]\n",
        "\n",
        "    models = {\n",
        "        'LinearSVC': LinearSVC(C=0.1, tol=1e-2, max_iter=1000),\n",
        "        'Multinomial NB': MultinomialNB(),\n",
        "        'Decision Tree': DecisionTreeClassifier(max_depth=10),\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "        'SGD': SGDClassifier(max_iter=1000, tol=1e-3),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
        "        'XGBoost': XGBClassifier(n_estimators=100, max_depth=10, random_state=42, eval_metric='logloss'),\n",
        "        'Stacking': StackingClassifier(\n",
        "            estimators=[\n",
        "                ('lr', LogisticRegression(max_iter=1000)),\n",
        "                ('xgb', XGBClassifier(n_estimators=100, max_depth=5, random_state=42, eval_metric='logloss')),\n",
        "                ('rf', RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42))\n",
        "            ],\n",
        "            final_estimator=LogisticRegression(max_iter=1000),\n",
        "            cv=5,\n",
        "            n_jobs=1\n",
        "        )\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        logger.info(f\"Training {name} for {db_name}\")\n",
        "        model_start = time.time()\n",
        "\n",
        "        if name == 'Stacking':\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "        elif name in ['Random Forest', 'XGBoost']:\n",
        "            model.fit(X_train_selected, y_train)\n",
        "            y_pred = model.predict(X_test_selected)\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "        model_end = time.time()\n",
        "\n",
        "        results[name] = {\n",
        "            'Precision': precision_score(y_test, y_pred),\n",
        "            'Recall': recall_score(y_test, y_pred),\n",
        "            'F1': f1_score(y_test, y_pred),\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            'Time (s)': model_end - model_start\n",
        "        }\n",
        "        logger.info(f\"Finished training {name} for {db_name} in {model_end - model_start:.2f} seconds\")\n",
        "\n",
        "    logger.info(f\"Completed training for {db_name} in {time.time() - start_time:.2f} seconds\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "T3fa3IEtBhSD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Main Driver ===\n",
        "start_total = time.time()\n",
        "logger.info(\"Starting entire process\")\n",
        "\n",
        "# Load your cached data\n",
        "hotel_df = prepare_data(data, 'yelp_hotel', sample_frac=1)\n",
        "rest_df = prepare_data(data, 'yelp_res', sample_frac=1)\n",
        "\n",
        "hotel_results = train_and_evaluate(hotel_df, 'yelp_hotel')\n",
        "rest_results = train_and_evaluate(rest_df, 'yelp_res')\n",
        "\n",
        "# === Summarize and PRINT OUTPUT ===\n",
        "logger.info(\"=== Model Performance Summary ===\")\n",
        "\n",
        "for db_name, results in [('yelp_hotel', hotel_results), ('yelp_res', rest_results)]:\n",
        "    print(f\"\\n=== Results for {db_name} ===\")\n",
        "    df_results = pd.DataFrame(results).T.round(3)\n",
        "    print(df_results)\n",
        "    print(\"\\n\")\n",
        "\n",
        "total_time = time.time() - start_total\n",
        "logger.info(f\"Total runtime: {total_time:.2f} seconds\")\n",
        "print(f\"Total runtime: {total_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D9hipkIROyxO",
        "outputId": "4fe97f4c-d466-42de-f9ff-fa5c19133ead"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Results for yelp_hotel ===\n",
            "                     Precision  Recall     F1  Accuracy  Time (s)\n",
            "LinearSVC                0.637   0.503  0.562     0.695     7.409\n",
            "Multinomial NB           0.609   0.429  0.504     0.670     0.232\n",
            "Decision Tree            0.577   0.371  0.452     0.649    76.377\n",
            "Logistic Regression      0.635   0.517  0.570     0.696     4.261\n",
            "SGD                      0.646   0.455  0.534     0.690     2.117\n",
            "Random Forest            0.604   0.254  0.358     0.644    97.504\n",
            "XGBoost                  0.593   0.432  0.500     0.663    15.661\n",
            "Stacking                 0.636   0.538  0.583     0.700  1211.116\n",
            "\n",
            "\n",
            "\n",
            "=== Results for yelp_res ===\n",
            "                     Precision  Recall     F1  Accuracy  Time (s)\n",
            "LinearSVC                0.594   0.457  0.516     0.644     4.657\n",
            "Multinomial NB           0.570   0.361  0.443     0.621     0.258\n",
            "Decision Tree            0.580   0.216  0.314     0.609    90.247\n",
            "Logistic Regression      0.594   0.470  0.525     0.646     7.371\n",
            "SGD                      0.604   0.390  0.474     0.640     2.714\n",
            "Random Forest            0.606   0.185  0.283     0.611   120.174\n",
            "XGBoost                  0.565   0.429  0.487     0.625    15.603\n",
            "Stacking                 0.593   0.510  0.548     0.651  1464.776\n",
            "\n",
            "\n",
            "Total runtime: 3624.72 seconds\n"
          ]
        }
      ]
    }
  ]
}